{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference PyTorch GPT2 Model with ONNX Runtime on CPU\n",
    "\n",
    "In this tutorial, you'll be introduced to how to load a GPT2 model from PyTorch, convert it to ONNX, and inference it using ONNX Runtime using IO Binding. Note that past state is used to get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites ##\n",
    "\n",
    "If you have Jupyter Notebook, you may directly run this notebook. We will use pip to install or upgrade [PyTorch](https://pytorch.org/), [OnnxRuntime](https://microsoft.github.io/onnxruntime/) and other required packages.\n",
    "\n",
    "Otherwise, you can setup a new environment. First, we install [AnaConda](https://www.anaconda.com/distribution/). Then open an AnaConda prompt window and run the following commands:\n",
    "\n",
    "```console\n",
    "conda create -n cpu_env python=3.8\n",
    "conda activate cpu_env\n",
    "conda install jupyter\n",
    "jupyter notebook\n",
    "```\n",
    "The last command will launch Jupyter Notebook and we can open this notebook in browser to continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/site-packages (1.10.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (0.11.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision) (1.21.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: onnxruntime==1.7.0 in /usr/local/lib/python3.9/site-packages (1.7.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/site-packages (from onnxruntime==1.7.0) (3.17.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/site-packages (from onnxruntime==1.7.0) (1.21.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.9/site-packages (from protobuf->onnxruntime==1.7.0) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting transformers==3.0.2\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2021.10.23-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.96-cp39-cp39-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Using cached tokenizers-0.8.1rc1.tar.gz (97 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from transformers==3.0.2) (1.21.3)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.1-py3-none-any.whl (96 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers==3.0.2) (1.16.0)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/local/opt/python@3.9/bin/python3.9 /usr/local/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py build_wheel /var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/tmpm_99zbqm\n",
      "       cwd: /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c\n",
      "  Complete output (236 lines):\n",
      "  /usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/setuptools/dist.py:484: UserWarning: Normalizing '0.8.1.rc1' to '0.8.1rc1'\n",
      "    warnings.warn(tmpl.format(**locals()))\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  creating build/lib/tokenizers\n",
      "  copying tokenizers/__init__.py -> build/lib/tokenizers\n",
      "  creating build/lib/tokenizers/models\n",
      "  copying tokenizers/models/__init__.py -> build/lib/tokenizers/models\n",
      "  creating build/lib/tokenizers/decoders\n",
      "  copying tokenizers/decoders/__init__.py -> build/lib/tokenizers/decoders\n",
      "  creating build/lib/tokenizers/normalizers\n",
      "  copying tokenizers/normalizers/__init__.py -> build/lib/tokenizers/normalizers\n",
      "  creating build/lib/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.py -> build/lib/tokenizers/pre_tokenizers\n",
      "  creating build/lib/tokenizers/processors\n",
      "  copying tokenizers/processors/__init__.py -> build/lib/tokenizers/processors\n",
      "  creating build/lib/tokenizers/trainers\n",
      "  copying tokenizers/trainers/__init__.py -> build/lib/tokenizers/trainers\n",
      "  creating build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/byte_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/base_tokenizer.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/__init__.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/char_level_bpe.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/implementations/bert_wordpiece.py -> build/lib/tokenizers/implementations\n",
      "  copying tokenizers/__init__.pyi -> build/lib/tokenizers\n",
      "  copying tokenizers/models/__init__.pyi -> build/lib/tokenizers/models\n",
      "  copying tokenizers/decoders/__init__.pyi -> build/lib/tokenizers/decoders\n",
      "  copying tokenizers/normalizers/__init__.pyi -> build/lib/tokenizers/normalizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/processors/__init__.pyi -> build/lib/tokenizers/processors\n",
      "  copying tokenizers/trainers/__init__.pyi -> build/lib/tokenizers/trainers\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "      Updating crates.io index\n",
      "      Updating git repository `https://github.com/n1t0/rayon-cond`\n",
      "  cargo rustc --lib --manifest-path Cargo.toml --features pyo3/extension-module --target x86_64-apple-darwin --release --verbose -- --crate-type cdylib -C link-arg=-undefined -C link-arg=dynamic_lookup\n",
      "  warning: unused manifest key: target.x86_64-apple-darwin.rustflags\n",
      "     Compiling proc-macro2 v1.0.30\n",
      "     Compiling unicode-xid v0.2.2\n",
      "     Compiling syn v1.0.80\n",
      "     Compiling libc v0.2.105\n",
      "     Compiling autocfg v1.0.1\n",
      "     Compiling memchr v2.4.1\n",
      "     Compiling serde v1.0.130\n",
      "     Compiling cfg-if v1.0.0\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro2-1.0.30/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' -C metadata=5005313c0c81a641 -C extra-filename=-5005313c0c81a641 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/proc-macro2-5005313c0c81a641 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name unicode_xid /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-xid-0.2.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=68b0a9cebb943fb3 -C extra-filename=-68b0a9cebb943fb3 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/syn-1.0.80/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"clone-impls\"' --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"extra-traits\"' --cfg 'feature=\"full\"' --cfg 'feature=\"parsing\"' --cfg 'feature=\"printing\"' --cfg 'feature=\"proc-macro\"' --cfg 'feature=\"quote\"' -C metadata=ff3adcceed57e542 -C extra-filename=-ff3adcceed57e542 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/syn-ff3adcceed57e542 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/libc-0.2.105/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=30ed86a99a74e2a1 -C extra-filename=-30ed86a99a74e2a1 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/libc-30ed86a99a74e2a1 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name autocfg /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/autocfg-1.0.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=73114e5ae6a09142 -C extra-filename=-73114e5ae6a09142 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/memchr-2.4.1/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=c4fb654b7bfcc9b1 -C extra-filename=-c4fb654b7bfcc9b1 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/memchr-c4fb654b7bfcc9b1 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/serde-1.0.130/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"derive\"' --cfg 'feature=\"serde_derive\"' --cfg 'feature=\"std\"' -C metadata=56bac802b48ba500 -C extra-filename=-56bac802b48ba500 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde-56bac802b48ba500 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name cfg_if --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/cfg-if-1.0.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=c0e053bfec46c381 -C extra-filename=-c0e053bfec46c381 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling serde_derive v1.0.130\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/serde_derive-1.0.130/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=4c1136fa957cd139 -C extra-filename=-4c1136fa957cd139 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde_derive-4c1136fa957cd139 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling lazy_static v1.4.0\n",
      "       Running `rustc --crate-name lazy_static /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/lazy_static-1.4.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=bb629a35e97e1032 -C extra-filename=-bb629a35e97e1032 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling ryu v1.0.5\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/ryu-1.0.5/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=30065f127c8b1d90 -C extra-filename=-30065f127c8b1d90 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/ryu-30065f127c8b1d90 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling scopeguard v1.1.0\n",
      "       Running `rustc --crate-name scopeguard /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/scopeguard-1.1.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=7812d61b31def5a2 -C extra-filename=-7812d61b31def5a2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling crossbeam-utils v0.8.5\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/crossbeam-utils-0.8.5/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"lazy_static\"' --cfg 'feature=\"std\"' -C metadata=f2fe2f2a9ed9e6e1 -C extra-filename=-f2fe2f2a9ed9e6e1 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/crossbeam-utils-f2fe2f2a9ed9e6e1 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling serde_json v1.0.68\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/serde_json-1.0.68/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=0e1d4c73264f1ce4 -C extra-filename=-0e1d4c73264f1ce4 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde_json-0e1d4c73264f1ce4 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling crossbeam-epoch v0.9.5\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/crossbeam-epoch-0.9.5/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"alloc\"' --cfg 'feature=\"lazy_static\"' --cfg 'feature=\"std\"' -C metadata=9a5010e034a5b5aa -C extra-filename=-9a5010e034a5b5aa --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/crossbeam-epoch-9a5010e034a5b5aa -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling proc-macro-hack v0.5.19\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro-hack-0.5.19/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=bcbfcf8126f8a9ed -C extra-filename=-bcbfcf8126f8a9ed --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/proc-macro-hack-bcbfcf8126f8a9ed -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling rayon-core v1.9.1\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-core-1.9.1/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=5c9e20cd619c7746 -C extra-filename=-5c9e20cd619c7746 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/rayon-core-5c9e20cd619c7746 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling getrandom v0.1.16\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/getrandom-0.1.16/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"std\"' -C metadata=4d08992828f69569 -C extra-filename=-4d08992828f69569 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/getrandom-4d08992828f69569 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling inventory v0.1.10\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/inventory-0.1.10/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=2098e9eef95a2895 -C extra-filename=-2098e9eef95a2895 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/inventory-2098e9eef95a2895 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling pkg-config v0.3.22\n",
      "       Running `rustc --crate-name pkg_config /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/pkg-config-0.3.22/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=8f3a72698eafbbf0 -C extra-filename=-8f3a72698eafbbf0 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling cc v1.0.71\n",
      "       Running `rustc --crate-name cc --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/cc-1.0.71/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=1d3dd1e0e9611a95 -C extra-filename=-1d3dd1e0e9611a95 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling unicode-width v0.1.9\n",
      "       Running `rustc --crate-name unicode_width /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-width-0.1.9/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=5a36c6d4574bed13 -C extra-filename=-5a36c6d4574bed13 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling smallvec v1.7.0\n",
      "       Running `rustc --crate-name smallvec --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/smallvec-1.7.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=e8cedfb381c3b538 -C extra-filename=-e8cedfb381c3b538 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling regex-syntax v0.6.25\n",
      "       Running `rustc --crate-name regex_syntax --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-syntax-0.6.25/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"unicode\"' --cfg 'feature=\"unicode-age\"' --cfg 'feature=\"unicode-bool\"' --cfg 'feature=\"unicode-case\"' --cfg 'feature=\"unicode-gencat\"' --cfg 'feature=\"unicode-perl\"' --cfg 'feature=\"unicode-script\"' --cfg 'feature=\"unicode-segment\"' -C metadata=a3de8f3d521c828d -C extra-filename=-a3de8f3d521c828d --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "       Running `rustc --crate-name regex_syntax --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-syntax-0.6.25/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"unicode\"' --cfg 'feature=\"unicode-age\"' --cfg 'feature=\"unicode-bool\"' --cfg 'feature=\"unicode-case\"' --cfg 'feature=\"unicode-gencat\"' --cfg 'feature=\"unicode-perl\"' --cfg 'feature=\"unicode-script\"' --cfg 'feature=\"unicode-segment\"' -C metadata=676edb9d47e603c5 -C extra-filename=-676edb9d47e603c5 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling either v1.6.1\n",
      "       Running `rustc --crate-name either /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/either-1.6.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"use_std\"' -C metadata=f1cebfa0668e993f -C extra-filename=-f1cebfa0668e993f --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling itoa v0.4.8\n",
      "       Running `rustc --crate-name itoa /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/itoa-0.4.8/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=9a2ffca532160e3d -C extra-filename=-9a2ffca532160e3d --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling erased-serde v0.3.16\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/erased-serde-0.3.16/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=f6b3d8ca00db0b46 -C extra-filename=-f6b3d8ca00db0b46 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/erased-serde-f6b3d8ca00db0b46 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling version_check v0.9.3\n",
      "       Running `rustc --crate-name version_check /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/version_check-0.9.3/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=49c0bd1fef649256 -C extra-filename=-49c0bd1fef649256 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling once_cell v1.8.0\n",
      "       Running `rustc --crate-name once_cell --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/once_cell-1.8.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"alloc\"' --cfg 'feature=\"default\"' --cfg 'feature=\"race\"' --cfg 'feature=\"std\"' -C metadata=60f82baf0c8089d8 -C extra-filename=-60f82baf0c8089d8 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling cfg-if v0.1.10\n",
      "       Running `rustc --crate-name cfg_if --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/cfg-if-0.1.10/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=d6a834be2d901781 -C extra-filename=-d6a834be2d901781 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling unindent v0.1.7\n",
      "       Running `rustc --crate-name unindent --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unindent-0.1.7/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=ba1d79ee981efd07 -C extra-filename=-ba1d79ee981efd07 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow`\n",
      "     Compiling ppv-lite86 v0.2.15\n",
      "       Running `rustc --crate-name ppv_lite86 --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/ppv-lite86-0.2.15/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"simd\"' --cfg 'feature=\"std\"' -C metadata=9cabeb8be5e8d37e -C extra-filename=-9cabeb8be5e8d37e --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling bitflags v1.3.2\n",
      "       Running `rustc --crate-name bitflags --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/bitflags-1.3.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=432547b55fa7feb5 -C extra-filename=-432547b55fa7feb5 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling ansi_term v0.11.0\n",
      "       Running `rustc --crate-name ansi_term /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/ansi_term-0.11.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=97bf21cf11a24a88 -C extra-filename=-97bf21cf11a24a88 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `rustc --crate-name itoa /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/itoa-0.4.8/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=b3e35c153a789be8 -C extra-filename=-b3e35c153a789be8 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling strsim v0.8.0\n",
      "       Running `rustc --crate-name strsim /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/strsim-0.8.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=9d8a9b9beb668694 -C extra-filename=-9d8a9b9beb668694 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling vec_map v0.8.2\n",
      "       Running `rustc --crate-name vec_map /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/vec_map-0.8.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=7a6f4274a4eea91f -C extra-filename=-7a6f4274a4eea91f --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling number_prefix v0.3.0\n",
      "       Running `rustc --crate-name number_prefix /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/number_prefix-0.3.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=817d65ca2acd2749 -C extra-filename=-817d65ca2acd2749 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling unicode_categories v0.1.1\n",
      "       Running `rustc --crate-name unicode_categories /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode_categories-0.1.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=0bf85d1db7310aa7 -C extra-filename=-0bf85d1db7310aa7 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `rustc --crate-name unindent --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unindent-0.1.7/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=e266fac5f00feadf -C extra-filename=-e266fac5f00feadf --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/memchr-c4fb654b7bfcc9b1/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/memchr-c4fb654b7bfcc9b1/build-script-build`\n",
      "     Compiling lock_api v0.3.4\n",
      "       Running `rustc --crate-name lock_api --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/lock_api-0.3.4/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"nightly\"' -C metadata=d871de13a2d640f1 -C extra-filename=-d871de13a2d640f1 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern scopeguard=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libscopeguard-7812d61b31def5a2.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde-56bac802b48ba500/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde-56bac802b48ba500/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde_derive-4c1136fa957cd139/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/libc-30ed86a99a74e2a1/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/syn-ff3adcceed57e542/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/crossbeam-utils-f2fe2f2a9ed9e6e1/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/ryu-30065f127c8b1d90/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/ryu-30065f127c8b1d90/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/crossbeam-epoch-9a5010e034a5b5aa/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/rayon-core-5c9e20cd619c7746/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/proc-macro2-5005313c0c81a641/build-script-build`\n",
      "     Compiling textwrap v0.11.0\n",
      "       Running `rustc --crate-name textwrap /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/textwrap-0.11.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=e2eae8c97a8b8539 -C extra-filename=-e2eae8c97a8b8539 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern unicode_width=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libunicode_width-5a36c6d4574bed13.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/getrandom-4d08992828f69569/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde_json-0e1d4c73264f1ce4/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/serde_json-0e1d4c73264f1ce4/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/proc-macro-hack-bcbfcf8126f8a9ed/build-script-build`\n",
      "     Compiling unicode-normalization-alignments v0.1.12\n",
      "       Running `rustc --crate-name unicode_normalization_alignments /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/unicode-normalization-alignments-0.1.12/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=d29daddabbbe4389 -C extra-filename=-d29daddabbbe4389 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern smallvec=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libsmallvec-e8cedfb381c3b538.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/inventory-2098e9eef95a2895/build-script-build`\n",
      "     Compiling itertools v0.8.2\n",
      "       Running `rustc --crate-name itertools /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/itertools-0.8.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"use_std\"' -C metadata=d3db403eab5d79b2 -C extra-filename=-d3db403eab5d79b2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern either=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libeither-f1cebfa0668e993f.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling memoffset v0.6.4\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/memoffset-0.6.4/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=b9f3916df2cbed23 -C extra-filename=-b9f3916df2cbed23 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/memoffset-b9f3916df2cbed23 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern autocfg=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libautocfg-73114e5ae6a09142.rlib --cap-lints allow`\n",
      "     Compiling rayon v1.5.1\n",
      "       Running `rustc --crate-name build_script_build --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/rayon-1.5.1/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=cdff58abaa921f21 -C extra-filename=-cdff58abaa921f21 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/rayon-cdff58abaa921f21 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern autocfg=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libautocfg-73114e5ae6a09142.rlib --cap-lints allow`\n",
      "     Compiling num-traits v0.2.14\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/num-traits-0.2.14/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=fe0e573ef4360eba -C extra-filename=-fe0e573ef4360eba --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/num-traits-fe0e573ef4360eba -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern autocfg=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libautocfg-73114e5ae6a09142.rlib --cap-lints allow`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/erased-serde-f6b3d8ca00db0b46/build-script-build`\n",
      "       Running `rustc --crate-name memchr --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/memchr-2.4.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=b55f9dc545592149 -C extra-filename=-b55f9dc545592149 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so' --cfg memchr_runtime_simd --cfg memchr_runtime_sse2 --cfg memchr_runtime_sse42 --cfg memchr_runtime_avx`\n",
      "       Running `rustc --crate-name memchr --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/memchr-2.4.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=a5f0fe1d1fcdd865 -C extra-filename=-a5f0fe1d1fcdd865 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow --cfg memchr_runtime_simd --cfg memchr_runtime_sse2 --cfg memchr_runtime_sse42 --cfg memchr_runtime_avx`\n",
      "       Running `rustc --crate-name libc /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/libc-0.2.105/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=265c8213ef7ddfd6 -C extra-filename=-265c8213ef7ddfd6 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so' --cfg freebsd11 --cfg libc_priv_mod_use --cfg libc_union --cfg libc_const_size_of --cfg libc_align --cfg libc_core_cvoid --cfg libc_packedN --cfg libc_cfg_target_vendor`\n",
      "       Running `rustc --crate-name crossbeam_utils --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/crossbeam-utils-0.8.5/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"lazy_static\"' --cfg 'feature=\"std\"' -C metadata=d5e63835f43884bd -C extra-filename=-d5e63835f43884bd --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern cfg_if=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libcfg_if-c0e053bfec46c381.rmeta --extern lazy_static=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblazy_static-bb629a35e97e1032.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `rustc --crate-name ryu --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/ryu-1.0.5/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=dd4694cc63694a39 -C extra-filename=-dd4694cc63694a39 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so' --cfg integer128 --cfg maybe_uninit`\n",
      "       Running `rustc --crate-name ryu --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/ryu-1.0.5/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=1b476223e0d23a5c -C extra-filename=-1b476223e0d23a5c --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow --cfg integer128 --cfg maybe_uninit`\n",
      "       Running `rustc --crate-name proc_macro2 --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro2-1.0.30/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' -C metadata=49a93da2ab668bf2 -C extra-filename=-49a93da2ab668bf2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern unicode_xid=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libunicode_xid-68b0a9cebb943fb3.rmeta --cap-lints allow --cfg lexerror_display --cfg hygiene --cfg use_proc_macro --cfg wrap_proc_macro --cfg proc_macro_span`\n",
      "       Running `rustc --crate-name proc_macro_hack --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/proc-macro-hack-0.5.19/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type proc-macro --emit=dep-info,link -C prefer-dynamic -C opt-level=3 -Cembed-bitcode=no -C metadata=216f7ea086700e60 -C extra-filename=-216f7ea086700e60 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern proc_macro --cap-lints allow`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/memoffset-b9f3916df2cbed23/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/rayon-cdff58abaa921f21/build-script-build`\n",
      "       Running `/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/num-traits-fe0e573ef4360eba/build-script-build`\n",
      "     Compiling aho-corasick v0.7.18\n",
      "       Running `rustc --crate-name aho_corasick --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/aho-corasick-0.7.18/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=4da69ee48b51ad6c -C extra-filename=-4da69ee48b51ad6c --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern memchr=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libmemchr-b55f9dc545592149.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `rustc --crate-name aho_corasick --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/aho-corasick-0.7.18/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=e40617bb9d8f89cf -C extra-filename=-e40617bb9d8f89cf --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern memchr=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libmemchr-a5f0fe1d1fcdd865.rmeta --cap-lints allow`\n",
      "     Compiling num_cpus v1.13.0\n",
      "       Running `rustc --crate-name num_cpus /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/num_cpus-1.13.0/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=73270946cf62284c -C extra-filename=-73270946cf62284c --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern libc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblibc-265c8213ef7ddfd6.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "       Running `rustc --crate-name getrandom --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/getrandom-0.1.16/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"std\"' -C metadata=5ec9021eed819276 -C extra-filename=-5ec9021eed819276 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern cfg_if=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libcfg_if-c0e053bfec46c381.rmeta --extern libc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblibc-265c8213ef7ddfd6.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling terminal_size v0.1.17\n",
      "       Running `rustc --crate-name terminal_size --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/terminal_size-0.1.17/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=52dd29a24dceab26 -C extra-filename=-52dd29a24dceab26 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern libc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblibc-265c8213ef7ddfd6.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling atty v0.2.14\n",
      "       Running `rustc --crate-name atty /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/atty-0.2.14/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no -C metadata=763ae273ba5adfd2 -C extra-filename=-763ae273ba5adfd2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern libc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblibc-265c8213ef7ddfd6.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling parking_lot_core v0.7.2\n",
      "       Running `rustc --crate-name parking_lot_core --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/parking_lot_core-0.7.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"nightly\"' -C metadata=6a8c3b50347e3686 -C extra-filename=-6a8c3b50347e3686 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern cfg_if=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libcfg_if-d6a834be2d901781.rmeta --extern libc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblibc-265c8213ef7ddfd6.rmeta --extern smallvec=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libsmallvec-e8cedfb381c3b538.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling crossbeam-channel v0.5.1\n",
      "       Running `rustc --crate-name crossbeam_channel --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/crossbeam-channel-0.5.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"crossbeam-utils\"' --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=32d47a35835a74b2 -C extra-filename=-32d47a35835a74b2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern cfg_if=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libcfg_if-c0e053bfec46c381.rmeta --extern crossbeam_utils=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libcrossbeam_utils-d5e63835f43884bd.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling quote v1.0.10\n",
      "       Running `rustc --crate-name quote --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/quote-1.0.10/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"proc-macro\"' -C metadata=5c6b5930fc618b62 -C extra-filename=-5c6b5930fc618b62 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern proc_macro2=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libproc_macro2-49a93da2ab668bf2.rmeta --cap-lints allow`\n",
      "       Running `rustc --crate-name memoffset /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/memoffset-0.6.4/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' -C metadata=7d7945ac5ae506d3 -C extra-filename=-7d7945ac5ae506d3 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so' --cfg tuple_ty --cfg allow_clippy --cfg maybe_uninit --cfg doctests`\n",
      "       Running `rustc --crate-name num_traits /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/num-traits-0.2.14/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"std\"' -C metadata=7760a29939b69d3a -C extra-filename=-7760a29939b69d3a --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so' --cfg has_i128 --cfg has_to_int_unchecked`\n",
      "     Compiling rand_core v0.5.1\n",
      "       Running `rustc --crate-name rand_core --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/rand_core-0.5.1/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"alloc\"' --cfg 'feature=\"getrandom\"' --cfg 'feature=\"std\"' -C metadata=23499868bae28d80 -C extra-filename=-23499868bae28d80 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern getrandom=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libgetrandom-5ec9021eed819276.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling clap v2.33.3\n",
      "       Running `rustc --crate-name clap /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/clap-2.33.3/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"ansi_term\"' --cfg 'feature=\"atty\"' --cfg 'feature=\"color\"' --cfg 'feature=\"default\"' --cfg 'feature=\"strsim\"' --cfg 'feature=\"suggestions\"' --cfg 'feature=\"vec_map\"' -C metadata=5d0911f98288a2f2 -C extra-filename=-5d0911f98288a2f2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern ansi_term=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libansi_term-97bf21cf11a24a88.rmeta --extern atty=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libatty-763ae273ba5adfd2.rmeta --extern bitflags=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libbitflags-432547b55fa7feb5.rmeta --extern strsim=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libstrsim-9d8a9b9beb668694.rmeta --extern textwrap=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libtextwrap-e2eae8c97a8b8539.rmeta --extern unicode_width=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libunicode_width-5a36c6d4574bed13.rmeta --extern vec_map=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libvec_map-7a6f4274a4eea91f.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "     Compiling regex v1.5.4\n",
      "       Running `rustc --crate-name regex --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-1.5.4/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"aho-corasick\"' --cfg 'feature=\"default\"' --cfg 'feature=\"memchr\"' --cfg 'feature=\"perf\"' --cfg 'feature=\"perf-cache\"' --cfg 'feature=\"perf-dfa\"' --cfg 'feature=\"perf-inline\"' --cfg 'feature=\"perf-literal\"' --cfg 'feature=\"std\"' --cfg 'feature=\"unicode\"' --cfg 'feature=\"unicode-age\"' --cfg 'feature=\"unicode-bool\"' --cfg 'feature=\"unicode-case\"' --cfg 'feature=\"unicode-gencat\"' --cfg 'feature=\"unicode-perl\"' --cfg 'feature=\"unicode-script\"' --cfg 'feature=\"unicode-segment\"' -C metadata=ee689155a510a9d9 -C extra-filename=-ee689155a510a9d9 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern aho_corasick=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libaho_corasick-4da69ee48b51ad6c.rmeta --extern memchr=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libmemchr-b55f9dc545592149.rmeta --extern regex_syntax=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libregex_syntax-676edb9d47e603c5.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "  error[E0658]: `if` is not allowed in a `const fn`\n",
      "    --> /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/clap-2.33.3/src/app/settings.rs:7:1\n",
      "     |\n",
      "  7  | / bitflags! {\n",
      "  8  | |     struct Flags: u64 {\n",
      "  9  | |         const SC_NEGATE_REQS       = 1;\n",
      "  10 | |         const SC_REQUIRED          = 1 << 1;\n",
      "  ...  |\n",
      "  51 | |     }\n",
      "  52 | | }\n",
      "     | |_^\n",
      "     |\n",
      "     = note: see issue #49146 <https://github.com/rust-lang/rust/issues/49146> for more information\n",
      "     = help: add `#![feature(const_if_match)]` to the crate attributes to enable\n",
      "     = note: this error originates in a macro (in Nightly builds, run with -Z macro-backtrace for more info)\n",
      "  \n",
      "  error[E0658]: `if` is not allowed in a `const fn`\n",
      "    --> /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/clap-2.33.3/src/args/settings.rs:6:1\n",
      "     |\n",
      "  6  | / bitflags! {\n",
      "  7  | |     struct Flags: u32 {\n",
      "  8  | |         const REQUIRED         = 1;\n",
      "  9  | |         const MULTIPLE         = 1 << 1;\n",
      "  ...  |\n",
      "  28 | |     }\n",
      "  29 | | }\n",
      "     | |_^\n",
      "     |\n",
      "     = note: see issue #49146 <https://github.com/rust-lang/rust/issues/49146> for more information\n",
      "     = help: add `#![feature(const_if_match)]` to the crate attributes to enable\n",
      "     = note: this error originates in a macro (in Nightly builds, run with -Z macro-backtrace for more info)\n",
      "  \n",
      "     Compiling onig_sys v69.7.1\n",
      "       Running `rustc --crate-name build_script_build /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/onig_sys-69.7.1/build.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type bin --emit=dep-info,link -C opt-level=3 -Cembed-bitcode=no -C metadata=af730836d087d7f7 -C extra-filename=-af730836d087d7f7 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/build/onig_sys-af730836d087d7f7 -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern cc=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libcc-1d3dd1e0e9611a95.rlib --extern pkg_config=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libpkg_config-8f3a72698eafbbf0.rlib --cap-lints allow`\n",
      "     Compiling parking_lot v0.10.2\n",
      "       Running `rustc --crate-name parking_lot --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/parking_lot-0.10.2/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"default\"' --cfg 'feature=\"nightly\"' -C metadata=10ec92144f21f721 -C extra-filename=-10ec92144f21f721 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern lock_api=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/liblock_api-d871de13a2d640f1.rmeta --extern parking_lot_core=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libparking_lot_core-6a8c3b50347e3686.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'`\n",
      "  error: aborting due to 2 previous errors\n",
      "  \n",
      "  For more information about this error, try `rustc --explain E0658`.\n",
      "       Running `rustc --crate-name regex --edition=2018 /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/regex-1.5.4/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"aho-corasick\"' --cfg 'feature=\"default\"' --cfg 'feature=\"memchr\"' --cfg 'feature=\"perf\"' --cfg 'feature=\"perf-cache\"' --cfg 'feature=\"perf-dfa\"' --cfg 'feature=\"perf-inline\"' --cfg 'feature=\"perf-literal\"' --cfg 'feature=\"std\"' --cfg 'feature=\"unicode\"' --cfg 'feature=\"unicode-age\"' --cfg 'feature=\"unicode-bool\"' --cfg 'feature=\"unicode-case\"' --cfg 'feature=\"unicode-gencat\"' --cfg 'feature=\"unicode-perl\"' --cfg 'feature=\"unicode-script\"' --cfg 'feature=\"unicode-segment\"' -C metadata=de96b186beb16c23 -C extra-filename=-de96b186beb16c23 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern aho_corasick=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libaho_corasick-e40617bb9d8f89cf.rmeta --extern memchr=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libmemchr-a5f0fe1d1fcdd865.rmeta --extern regex_syntax=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps/libregex_syntax-a3de8f3d521c828d.rmeta --cap-lints allow`\n",
      "  error: could not compile `clap`.\n",
      "  \n",
      "  Caused by:\n",
      "    process didn't exit successfully: `rustc --crate-name clap /Users/haobogu/.cargo/registry/src/github.com-1ecc6299db9ec823/clap-2.33.3/src/lib.rs --error-format=json --json=diagnostic-rendered-ansi,artifacts --crate-type lib --emit=dep-info,metadata,link -C opt-level=3 -Cembed-bitcode=no --cfg 'feature=\"ansi_term\"' --cfg 'feature=\"atty\"' --cfg 'feature=\"color\"' --cfg 'feature=\"default\"' --cfg 'feature=\"strsim\"' --cfg 'feature=\"suggestions\"' --cfg 'feature=\"vec_map\"' -C metadata=5d0911f98288a2f2 -C extra-filename=-5d0911f98288a2f2 --out-dir /private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps --target x86_64-apple-darwin -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps -L dependency=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/release/deps --extern ansi_term=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libansi_term-97bf21cf11a24a88.rmeta --extern atty=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libatty-763ae273ba5adfd2.rmeta --extern bitflags=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libbitflags-432547b55fa7feb5.rmeta --extern strsim=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libstrsim-9d8a9b9beb668694.rmeta --extern textwrap=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libtextwrap-e2eae8c97a8b8539.rmeta --extern unicode_width=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libunicode_width-5a36c6d4574bed13.rmeta --extern vec_map=/private/var/folders/22/wsxdmty94v32jy85s716h3p00000gp/T/pip-install-paesvux3/tokenizers_be249548d0e24be084428c57868ff66c/target/x86_64-apple-darwin/release/deps/libvec_map-7a6f4274a4eea91f.rmeta --cap-lints allow -C 'link-args=-Wl,-install_name,@rpath/tokenizers.cpython-39-darwin.so'` (exit code: 1)\n",
      "  warning: build failed, waiting for other jobs to finish...\n",
      "  error: build failed\n",
      "  error: cargo failed with code: 101\n",
      "  \n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "Failed to build tokenizers\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: onnxconverter_common in /usr/local/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (5.8.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.9/site-packages (2021.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (1.3.4)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.9/site-packages (8.0.0)\n",
      "Requirement already satisfied: py3nvml in /usr/local/lib/python3.9/site-packages (0.2.6)\n",
      "Requirement already satisfied: netron in /usr/local/lib/python3.9/site-packages (5.3.1)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/site-packages (15.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.9/site-packages (from onnx) (3.10.0.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.9/site-packages (from onnx) (1.21.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from onnx) (1.16.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/site-packages (from onnx) (3.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: xmltodict in /usr/local/lib/python3.9/site-packages (from py3nvml) (0.12.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/site-packages (from coloredlogs) (10.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install Py.Torch 1.6.0 and OnnxRuntime 1.5.1 for CPU-only\n",
    "import sys\n",
    "if sys.platform == 'darwin': # Mac\n",
    "    !{sys.executable} -m pip install --upgrade torch torchvision\n",
    "else:\n",
    "    !{sys.executable} -m pip install --upgrade torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!{sys.executable} -m pip install onnxruntime\n",
    "\n",
    "# Install other packages used in this notebook.\n",
    "!{sys.executable} -m pip install transformers\n",
    "!{sys.executable} -m pip install onnx onnxconverter_common psutil pytz pandas py-cpuinfo py3nvml netron coloredlogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a cache directory to store pretrained model.\n",
    "cache_dir = os.path.join(\".\", \"cache_models\")\n",
    "if not os.path.exists(cache_dir):\n",
    "    os.makedirs(cache_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert GPT2 model from PyTorch to ONNX ##\n",
    "\n",
    "We have a script [convert_to_onnx.py](https://github.com/microsoft/onnxruntime/blob/master/onnxruntime/python/tools/transformers/convert_to_onnx.py) that could help you to convert GPT2 with past state to ONNX. \n",
    "\n",
    "The script accepts a pretrained model name or path of a checkpoint directory as input, and converts the model to ONNX. It also verifies that the ONNX model could generate same input as the pytorch model. The usage is like \n",
    "```\n",
    "python -m onnxruntime.transformers.convert_to_onnx -m model_name_or_path --output gpt2.onnx -o -p fp32|fp16|int8\n",
    "```\n",
    "The -p option can be used to choose the precision: fp32 (float32), fp16 (mixed precision) or int8 (quantization). The -o option will generate optimized model, which is required for fp16 or int8.\n",
    "\n",
    "Here we use a pretrained model as example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 3.0 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 5.5 MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers) (1.21.3)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.3.1-py3-none-any.whl (9.7 kB)\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 2.9 MB/s \n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Using cached regex-2021.10.23-cp39-cp39-macosx_10_9_x86_64.whl (288 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 3.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers) (3.10.0.2)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.1-py3-none-any.whl (96 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Using cached charset_normalizer-2.0.7-py3-none-any.whl (38 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.0.3-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Installing collected packages: urllib3, pyparsing, idna, charset-normalizer, certifi, tqdm, requests, regex, pyyaml, packaging, joblib, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed certifi-2021.10.8 charset-normalizer-2.0.7 click-8.0.3 filelock-3.3.1 huggingface-hub-0.0.19 idna-3.3 joblib-1.1.0 packaging-21.0 pyparsing-3.0.1 pyyaml-6.0 regex-2021.10.23 requests-2.26.0 sacremoses-0.0.46 tokenizers-0.10.3 tqdm-4.62.3 transformers-4.11.3 urllib3-1.26.7\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 665/665 [00:00<00:00, 185kB/s]\n",
      "Downloading: 100%|██████████| 523M/523M [02:39<00:00, 3.44MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.transformers.gpt2_helper import Gpt2Helper, MyGPT2LMHeadModel\n",
    "from transformers import AutoConfig\n",
    "import torch\n",
    "\n",
    "model_name_or_path = \"gpt2\"\n",
    "config = AutoConfig.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
    "model = MyGPT2LMHeadModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
    "device = torch.device(\"cpu\")\n",
    "model.eval().to(device)\n",
    "\n",
    "print(model.config)\n",
    "\n",
    "num_attention_heads = model.config.n_head\n",
    "hidden_size = model.config.n_embd\n",
    "num_layer = model.config.n_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/onnx/utils.py:100: UserWarning: `example_outputs' is deprecated and ignored. Will be removed in next PyTorch release.\n",
      "  warnings.warn(\"`example_outputs' is deprecated and ignored. Will be removed in \"\n",
      "/usr/local/lib/python3.9/site-packages/torch/onnx/utils.py:103: UserWarning: `use_external_data_format' is deprecated and ignored. Will be removed in next PyTorch release. The code will work as it is False if models are not larger than 2GB, Otherwise set to False because of size limits imposed by Protocol Buffers.\n",
      "  warnings.warn(\"`use_external_data_format' is deprecated and ignored. Will be removed in next \"\n",
      "/usr/local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:705: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "/usr/local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:250: TracerWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  past_key, past_value = layer_past\n",
      "/usr/local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py:182: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  attn_weights = attn_weights / (float(value.size(-1)) ** 0.5)\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"gpt2.onnx\"\n",
    "Gpt2Helper.export_onnx(model, device, onnx_model_path) # add parameter use_external_data_format=True when model size > 2 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Inference using Huggingface Transformers##\n",
    "\n",
    "In the following, we will use an example input to get the output from PyTorch for comparison purpose.\n",
    "For the first inference, there is no any past state. We can prepare empty state for input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 1.04M/1.04M [00:01<00:00, 689kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:01<00:00, 394kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[50256, 50256, 50256, 50256, 13466,  7541,   287, 15489,  1989],\n",
      "        [ 1456,   318,   281,  1672,   286,   308,   457,    17,  2746]])\n",
      "attention_mask tensor([[0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "position_ids tensor([[0, 0, 0, 0, 0, 1, 2, 3, 4],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "EXAMPLE_Text = ['best hotel in bay area', 'here is an example of gpt2 model']\n",
    "\n",
    "def get_tokenizer(model_name_or_path, cache_dir):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, cache_dir=cache_dir)\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    #okenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    return tokenizer\n",
    "\n",
    "def get_example_inputs(prompt_text=EXAMPLE_Text):    \n",
    "    tokenizer = get_tokenizer(model_name_or_path, cache_dir)\n",
    "    encodings_dict = tokenizer.batch_encode_plus(prompt_text, padding=True)\n",
    "\n",
    "    input_ids = torch.tensor(encodings_dict['input_ids'], dtype=torch.int64)\n",
    "    attention_mask = torch.tensor(encodings_dict['attention_mask'], dtype=torch.float32)\n",
    "    position_ids = (attention_mask.long().cumsum(-1) - 1)\n",
    "    position_ids.masked_fill_(position_ids < 0, 0)\n",
    "\n",
    "    #Empty Past State for generating first word\n",
    "    empty_past = []\n",
    "    batch_size = input_ids.size(0)\n",
    "    sequence_length = input_ids.size(1)\n",
    "    past_shape = [2, batch_size, num_attention_heads, 0, hidden_size // num_attention_heads]\n",
    "    for i in range(num_layer):\n",
    "        empty_past.append(torch.empty(past_shape).type(torch.float32).to(device))\n",
    "       \n",
    "    return input_ids, attention_mask, position_ids, empty_past\n",
    "\n",
    "\n",
    "from transformers import GPT2LMHeadModel\n",
    "torch_model = GPT2LMHeadModel.from_pretrained(model_name_or_path, config=config, cache_dir=cache_dir)\n",
    "device = torch.device(\"cpu\")\n",
    "torch_model.eval().to(device)\n",
    "\n",
    "input_ids, attention_mask, position_ids, empty_past = get_example_inputs()\n",
    "print(\"input_ids\", input_ids)\n",
    "print(\"attention_mask\", attention_mask)\n",
    "print(\"position_ids\", position_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch_output = torch_model(input_ids, past=empty_past, attention_mask=attention_mask, position_ids=position_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime Inference ##\n",
    "\n",
    "We can use ONNX Runtime to inference. The inputs are dictionary with name and numpy array as value, and the output is list of numpy array. Note that both input and output are in CPU. When you run the inference in GPU, it will involve data copy between CPU and GPU for input and output.\n",
    "\n",
    "Let's create an inference session for ONNX Runtime given the exported ONNX model, and see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': array([[50256, 50256, 50256, 50256, 13466,  7541,   287, 15489,  1989],\n",
      "       [ 1456,   318,   281,  1672,   286,   308,   457,    17,  2746]],\n",
      "      dtype=int64), 'attention_mask': array([[0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
      "       [1., 1., 1., 1., 1., 1., 1., 1., 1.]], dtype=float32), 'position_ids': array([[0, 0, 0, 0, 0, 1, 2, 3, 4],\n",
      "       [0, 1, 2, 3, 4, 5, 6, 7, 8]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import numpy\n",
    "\n",
    "input_ids, attention_mask, position_ids, empty_past = get_example_inputs()\n",
    "\n",
    "onnx_model_path = \"gpt2.onnx\"\n",
    "session = onnxruntime.InferenceSession(onnx_model_path)\n",
    "ort_inputs = {'input_ids': numpy.ascontiguousarray(input_ids.cpu().numpy()),\n",
    "              'attention_mask' : numpy.ascontiguousarray(attention_mask.cpu().numpy()),\n",
    "              'position_ids': numpy.ascontiguousarray(position_ids.cpu().numpy())\n",
    "             }\n",
    "print(ort_inputs)\n",
    "for i, past_i in enumerate(empty_past):\n",
    "    ort_inputs[f'past_{i}'] = numpy.ascontiguousarray(past_i.cpu().numpy())\n",
    "ort_outputs = session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the outputs from PyTorch and ONNX Runtime. Logits are very close (max difference is 1E-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max logits diff (ignored padding) tensor(6.8665e-05)\n"
     ]
    }
   ],
   "source": [
    "logits_masked_diff = (torch_output[0] - ort_outputs[0]) * attention_mask.unsqueeze(2)\n",
    "max_logits_diff = logits_masked_diff.abs().max()\n",
    "print(\"max logits diff (ignored padding)\", max_logits_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Runtime Inference with IO Binding ##\n",
    "\n",
    "To avoid data copy for input and output, ONNX Runtime also supports IO Binding. User could provide some buffer for input and outputs. For GPU inference, the buffer can be in GPU to reduce memory copy between CPU and GPU. This is helpful for high performance inference in GPU. For GPT-2, IO Binding might help the performance when batch size or (past) sequence length is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_io_binding(session, config, input_ids, position_ids, attention_mask, past):\n",
    "    output_shapes = Gpt2Helper.get_output_shapes(batch_size=input_ids.size(0),\n",
    "                                                 past_sequence_length=past[0].size(3),\n",
    "                                                 sequence_length=input_ids.size(1),\n",
    "                                                 config=config)\n",
    "    print(output_shapes)\n",
    "    output_buffers = Gpt2Helper.get_output_buffers(output_shapes, device)\n",
    "\n",
    "    print(output_buffers)\n",
    "    io_binding = Gpt2Helper.prepare_io_binding(session, input_ids, position_ids, attention_mask, past,\n",
    "                                               output_buffers, output_shapes)\n",
    "    session.run_with_iobinding(io_binding)\n",
    "\n",
    "    outputs = Gpt2Helper.get_outputs_from_io_binding_buffer(session, output_buffers, output_shapes,\n",
    "                                                            return_numpy=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result is exactly same with/without IO Binding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': [2, 9, 50257], 'present_0': [2, 2, 12, 9, 64], 'present_1': [2, 2, 12, 9, 64], 'present_2': [2, 2, 12, 9, 64], 'present_3': [2, 2, 12, 9, 64], 'present_4': [2, 2, 12, 9, 64], 'present_5': [2, 2, 12, 9, 64], 'present_6': [2, 2, 12, 9, 64], 'present_7': [2, 2, 12, 9, 64], 'present_8': [2, 2, 12, 9, 64], 'present_9': [2, 2, 12, 9, 64], 'present_10': [2, 2, 12, 9, 64], 'present_11': [2, 2, 12, 9, 64]}\n",
      "{'logits': tensor([8.4078e-45, 9.8091e-45, 1.1210e-44,  ..., 7.6294e-06, 1.5259e-05,\n",
      "        3.8147e-05]), 'present_0': tensor([ 2.7551e-39,  7.7592e-37,         nan,  ...,  7.3708e-43,\n",
      "        -9.1699e+27,  7.3708e-43]), 'present_1': tensor([-0.2771,  2.7640, -0.6938,  ...,  0.1836,  0.2120,  1.4961]), 'present_2': tensor([-0.0141, -0.1919,  0.1306,  ..., -0.8329, -0.3928, -0.2892]), 'present_3': tensor([ 0.2841,  0.0346, -0.8563,  ..., -0.1179,  0.1191,  0.3991]), 'present_4': tensor([-0.1280, -0.7493,  0.6054,  ...,  0.1108,  0.0243, -0.0911]), 'present_5': tensor([ 0.0877, -0.1777, -0.2034,  ...,  0.8704, -0.8224,  0.3544]), 'present_6': tensor([ 0.6488,  0.1956,  1.4155,  ...,  0.5815, -0.7382,  0.2567]), 'present_7': tensor([-2.2676e+24,  7.3708e-43, -2.2676e+24,  ...,  7.3708e-43,\n",
      "        -1.0068e+26,  7.3708e-43]), 'present_8': tensor([-1.0069e+26,  7.3708e-43, -1.0069e+26,  ...,  7.3708e-43,\n",
      "        -1.1434e+26,  7.3708e-43]), 'present_9': tensor([-1.1898e+26,  7.3708e-43, -1.1892e+26,  ...,  7.3708e-43,\n",
      "        -1.3268e+26,  7.3708e-43]), 'present_10': tensor([-1.3269e+26,  7.3708e-43, -1.3272e+26,  ...,  7.3708e-43,\n",
      "        -8.8224e+27,  7.3708e-43]), 'present_11': tensor([-9.4676e+27,  7.3708e-43, -9.4677e+27,  ...,  7.3708e-43,\n",
      "        -2.5150e+30,  7.3708e-43])}\n",
      "IO Binding result is good\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, position_ids, empty_past = get_example_inputs()\n",
    "outputs = inference_with_io_binding(session, config, input_ids, position_ids, attention_mask, empty_past)\n",
    "for i in range(len(outputs)):\n",
    "    assert torch.eq(outputs[i], torch.from_numpy(ort_outputs[i])).all()\n",
    "print(\"IO Binding result is good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Text Generation ##\n",
    "\n",
    "Here is an example for text generation using ONNX Runtime or PyTorch. For ONNX Runtime, IO Binding is used for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generation(tokenizer, input_text, ort_session=None, num_tokens_to_produce = 30):\n",
    "    use_onnxruntime = (ort_session is not None)\n",
    "    print(\"Text generation using\", \"OnnxRuntime\" if use_onnxruntime else \"PyTorch\", \"...\")\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    input_ids, attention_mask, position_ids, past = get_example_inputs(input_text)\n",
    "    batch_size = input_ids.size(0)\n",
    "\n",
    "    has_eos = torch.zeros(batch_size, dtype=torch.bool)\n",
    "\n",
    "    all_token_ids = input_ids.clone()\n",
    "\n",
    "    for step in range(num_tokens_to_produce):\n",
    "        if ort_session is not None:\n",
    "            outputs = inference_with_io_binding(ort_session, config, input_ids, position_ids, attention_mask, past)\n",
    "        else:\n",
    "            outputs = torch_model(input_ids, attention_mask=attention_mask, position_ids=position_ids, past=past)  \n",
    "\n",
    "        next_token_logits = outputs[0][:, -1, :]\n",
    "        # Greedy approach is used here. You can easily extend it to use beam search and sampling to pick next tokens.\n",
    "        next_tokens = torch.argmax(next_token_logits, dim=-1)\n",
    "\n",
    "        has_eos = has_eos | (next_tokens == eos_token_id)\n",
    "        tokens_to_add = next_tokens.masked_fill(has_eos, eos_token_id)\n",
    "        all_token_ids = torch.cat([all_token_ids, tokens_to_add.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "        # Update input_ids, attention_mask, position_ids and past\n",
    "        input_ids = tokens_to_add.clone().detach().reshape([batch_size, 1]).to(device)    \n",
    "        position_ids = (position_ids[:,-1] + 1).reshape(batch_size,1)\n",
    "        attention_mask = torch.cat([attention_mask, torch.ones([batch_size, 1]).type_as(attention_mask)], 1).to(device)    \n",
    "\n",
    "        past = []\n",
    "        if not use_onnxruntime:\n",
    "            past = list(outputs[1]) # past in torch output is tuple\n",
    "        else:\n",
    "            for i in range(num_layer):\n",
    "                past_i = torch.from_numpy(outputs[i + 1]) if isinstance(outputs[i + 1], numpy.ndarray) else outputs[i + 1].clone().detach()\n",
    "                past.append(past_i.to(device))\n",
    "\n",
    "        if torch.all(has_eos):\n",
    "            break\n",
    "\n",
    "    for i, output in enumerate(all_token_ids):\n",
    "        print(\"------------\")\n",
    "        print(tokenizer.decode(output, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generation using OnnxRuntime ...\n",
      "------------\n",
      "best hotel in bay area.\n",
      "\n",
      "The hotel is located in the historic Bayview neighborhood of San Francisco.\n",
      "\n",
      "The hotel is open daily from 9 a.m.\n",
      "------------\n",
      "here is an example of gpt2 model.\n",
      "\n",
      "The gpt2 model is a simple, but powerful, way to generate a GPT2-like data structure. It is a\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer(model_name_or_path, cache_dir)\n",
    "input_text = EXAMPLE_Text\n",
    "test_generation(tokenizer, input_text, ort_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use PyTorch to run again and we can see that the result is exactly same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generation using PyTorch ...\n",
      "------------\n",
      "best hotel in bay area.\n",
      "\n",
      "The hotel is located in the historic Bayview neighborhood of San Francisco.\n",
      "\n",
      "The hotel is open daily from 9 a.m.\n",
      "------------\n",
      "here is an example of gpt2 model.\n",
      "\n",
      "The gpt2 model is a simple, but powerful, way to generate a GPT2-like data structure. It is a\n"
     ]
    }
   ],
   "source": [
    "test_generation(tokenizer, input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Int8 Quantization ##\n",
    "Next, we will apply dynamic quantization to the model. We optimize the model before quantization to get better performance.\n",
    "\n",
    "Note that text generation result from fp32 and int8 models could be quite different. User shall evaluate the precision metric for your application for both fp32 and int8 models. If the quality of int8 model result is acceptable, you will be glad to find that it is faster than fp32 model in inference. \n",
    "\n",
    "Note that you can leverage [quantization aware training (QAT)](https://pytorch.org/blog/introduction-to-quantization-on-pytorch/) for accuracy improvement if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: onnxruntime.quantization.quantize is deprecated.\n",
      "         Please use quantize_static for static quantization, quantize_dynamic for dynamic quantization.\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.transformers.quantize_helper import QuantizeHelper\n",
    "\n",
    "optimized_fp32_model_path = \"gpt2_fp32.onnx\"\n",
    "quantized_int8_model_path = \"gpt2_int8.onnx\"\n",
    "Gpt2Helper.optimize_onnx(\"gpt2.onnx\", optimized_fp32_model_path, False, model.config.num_attention_heads, model.config.hidden_size)\n",
    "QuantizeHelper.quantize_onnx_model(optimized_fp32_model_path, quantized_int8_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generation using OnnxRuntime ...\n",
      "------------\n",
      "bert model optimization, and the NLP model is a generalizable and robust model.\n"
     ]
    }
   ],
   "source": [
    "session_int8 = onnxruntime.InferenceSession(quantized_int8_model_path)\n",
    "input_text = ['bert model optimization']\n",
    "test_generation(tokenizer, input_text, ort_session=session_int8, num_tokens_to_produce=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark ##\n",
    "There is a tool benchmark_gpt2.py, which can be used to measure the performance of GPT-2 by PyTorch, ONNX Runtime without/with IO Binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen/Parallel:\n",
      "\tat::get_num_threads() : 12\n",
      "\tat::get_num_interop_threads() : 6\n",
      "OpenMP 2019\n",
      "\tomp_get_max_threads() : 12\n",
      "Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191125 for Intel(R) 64 architecture applications\n",
      "\tmkl_get_max_threads() : 12\n",
      "Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "std::thread::hardware_concurrency() : 12\n",
      "Environment variables:\n",
      "\tOMP_NUM_THREADS : [not set]\n",
      "\tMKL_NUM_THREADS : [not set]\n",
      "ATen parallel backend: OpenMP\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-30 18:44:40.720277: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\n",
      "Arguments:Namespace(batch_sizes=[1], cache_dir='.\\\\cache_models', include_copy_output_latency=False, model_class='GPT2LMHeadModel', model_name_or_path='gpt2', onnx_dir='.\\\\onnx_models', optimize_onnx=True, past_sequence_lengths=[8, 16, 32, 64, 128, 256], precision=<Precision.FLOAT32: 'fp32'>, result_csv=None, test_times=100, thread_num=-1, torchscript=False, use_gpu=False, validate_onnx=False, verbose=False)\n",
      "PyTorch Version:1.6.0+cpu\n",
      "Transformers Version:3.0.2\n",
      "Onnxruntime Version:1.5.1\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:714: FutureWarning: The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\n",
      "  FutureWarning,\n",
      "Shapes: input_ids=torch.Size([1, 1]) past=torch.Size([2, 1, 12, 1, 64]) output=torch.Size([1, 1, 50257]) present=torch.Size([2, 1, 12, 2, 64])\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:560: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:166: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  w = w / (float(v.size(-1)) ** 0.5)\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:171: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  mask = self.bias[:, :, ns - nd : ns, :ns]\n",
      "Fused LayerNormalization count: 25\n",
      "Fused FastGelu count: 12\n",
      "Fused Attention(with past) count: 12\n",
      "Graph pruned: 0 inputs, 0 outputs and 741 nodes are removed\n",
      "Graph pruned: 0 inputs, 0 outputs and 312 nodes are removed\n",
      "postprocess: remove Reshape count:48\n",
      "Fused FastGelu(add bias) count: 12\n",
      "opset verion: 11\n",
      "Output model to .\\onnx_models\\gpt2_past_fp32.onnx\n",
      "batch_size=1, past_sequence_length=8, torch_latency=40.68, ort_latency=24.07, ort_io_latency=24.03\n",
      "batch_size=1, past_sequence_length=16, torch_latency=40.87, ort_latency=23.14, ort_io_latency=22.27\n",
      "batch_size=1, past_sequence_length=32, torch_latency=41.36, ort_latency=23.74, ort_io_latency=23.05\n",
      "batch_size=1, past_sequence_length=64, torch_latency=42.97, ort_latency=26.25, ort_io_latency=23.64\n",
      "batch_size=1, past_sequence_length=128, torch_latency=44.30, ort_latency=30.48, ort_io_latency=25.85\n",
      "batch_size=1, past_sequence_length=256, torch_latency=54.77, ort_latency=40.60, ort_io_latency=28.20\n",
      "Results are saved to file benchmark_result_20200930-184558.csv\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m onnxruntime.transformers.benchmark_gpt2 -m gpt2 -o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATen/Parallel:\n",
      "\tat::get_num_threads() : 12\n",
      "\tat::get_num_interop_threads() : 6\n",
      "OpenMP 2019\n",
      "\tomp_get_max_threads() : 12\n",
      "Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191125 for Intel(R) 64 architecture applications\n",
      "\tmkl_get_max_threads() : 12\n",
      "Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "std::thread::hardware_concurrency() : 12\n",
      "Environment variables:\n",
      "\tOMP_NUM_THREADS : [not set]\n",
      "\tMKL_NUM_THREADS : [not set]\n",
      "ATen parallel backend: OpenMP\n",
      "\n",
      "Warning: onnxruntime.quantization.quantize is deprecated.\n",
      "         Please use quantize_static for static quantization, quantize_dynamic for dynamic quantization.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-30 18:47:09.756025: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\n",
      "Arguments:Namespace(batch_sizes=[1], cache_dir='.\\\\cache_models', include_copy_output_latency=False, model_class='GPT2LMHeadModel', model_name_or_path='gpt2', onnx_dir='.\\\\onnx_models', optimize_onnx=True, past_sequence_lengths=[8, 16, 32, 64, 128, 256], precision=<Precision.INT8: 'int8'>, result_csv=None, test_times=100, thread_num=-1, torchscript=False, use_gpu=False, validate_onnx=False, verbose=False)\n",
      "PyTorch Version:1.6.0+cpu\n",
      "Transformers Version:3.0.2\n",
      "Onnxruntime Version:1.5.1\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:714: FutureWarning: The `past` argument is deprecated and will be removed in a future version, use `past_key_values` instead.\n",
      "  FutureWarning,\n",
      "Shapes: input_ids=torch.Size([1, 1]) past=torch.Size([2, 1, 12, 1, 64]) output=torch.Size([1, 1, 50257]) present=torch.Size([2, 1, 12, 2, 64])\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:560: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert batch_size > 0, \"batch_size has to be defined and > 0\"\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:166: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  w = w / (float(v.size(-1)) ** 0.5)\n",
      "d:\\git\\transformers\\src\\transformers\\modeling_gpt2.py:171: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  mask = self.bias[:, :, ns - nd : ns, :ns]\n",
      "Fused LayerNormalization count: 25\n",
      "Fused FastGelu count: 12\n",
      "Fused Attention(with past) count: 12\n",
      "Graph pruned: 0 inputs, 0 outputs and 741 nodes are removed\n",
      "Graph pruned: 0 inputs, 0 outputs and 312 nodes are removed\n",
      "postprocess: remove Reshape count:48\n",
      "Fused FastGelu(add bias) count: 12\n",
      "opset verion: 11\n",
      "Output model to .\\onnx_models\\gpt2_past_int8.onnx\n",
      "quantizing model...\n",
      "Size of full precision ONNX model(MB):621.9615631103516\n",
      "quantized model saved to:.\\onnx_models\\gpt2_past_int8.onnx\n",
      "Size of quantized ONNX model(MB):155.89412593841553\n",
      "Size of full precision Torch model(MB):486.7606954574585\n",
      "Size of quantized Torch model(MB):280.60562801361084\n",
      "finished quantizing model\n",
      "batch_size=1, past_sequence_length=8, torch_latency=19.50, ort_latency=11.35, ort_io_latency=11.24\n",
      "batch_size=1, past_sequence_length=16, torch_latency=20.13, ort_latency=11.53, ort_io_latency=10.24\n",
      "batch_size=1, past_sequence_length=32, torch_latency=20.54, ort_latency=12.05, ort_io_latency=11.97\n",
      "batch_size=1, past_sequence_length=64, torch_latency=21.29, ort_latency=13.90, ort_io_latency=12.15\n",
      "batch_size=1, past_sequence_length=128, torch_latency=23.40, ort_latency=19.22, ort_io_latency=13.96\n",
      "batch_size=1, past_sequence_length=256, torch_latency=30.26, ort_latency=29.05, ort_io_latency=16.77\n",
      "Results are saved to file benchmark_result_20200930-184855.csv\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m onnxruntime.transformers.benchmark_gpt2 -m gpt2 -o --precision int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that quantized model has significant speed up (close to 2x).\n",
    "\n",
    "### Test Environment ###\n",
    "The following is the hardware of the test machine, and software version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gpu\": {\n",
      "    \"driver_version\": \"451.67\",\n",
      "    \"devices\": [\n",
      "      {\n",
      "        \"memory_total\": 8589934592,\n",
      "        \"memory_available\": 8480882688,\n",
      "        \"name\": \"GeForce GTX 1070\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"cpu\": {\n",
      "    \"brand\": \"Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz\",\n",
      "    \"cores\": 6,\n",
      "    \"logical_cores\": 12,\n",
      "    \"hz\": \"3.1920 GHz\",\n",
      "    \"l2_cache\": \"1536 KB\",\n",
      "    \"flags\": [\n",
      "      \"3dnow\",\n",
      "      \"3dnowprefetch\",\n",
      "      \"abm\",\n",
      "      \"acpi\",\n",
      "      \"adx\",\n",
      "      \"aes\",\n",
      "      \"apic\",\n",
      "      \"avx\",\n",
      "      \"avx2\",\n",
      "      \"bmi1\",\n",
      "      \"bmi2\",\n",
      "      \"clflush\",\n",
      "      \"clflushopt\",\n",
      "      \"cmov\",\n",
      "      \"cx16\",\n",
      "      \"cx8\",\n",
      "      \"de\",\n",
      "      \"dtes64\",\n",
      "      \"dts\",\n",
      "      \"erms\",\n",
      "      \"est\",\n",
      "      \"f16c\",\n",
      "      \"fma\",\n",
      "      \"fpu\",\n",
      "      \"fxsr\",\n",
      "      \"hle\",\n",
      "      \"ht\",\n",
      "      \"hypervisor\",\n",
      "      \"ia64\",\n",
      "      \"invpcid\",\n",
      "      \"lahf_lm\",\n",
      "      \"mca\",\n",
      "      \"mce\",\n",
      "      \"mmx\",\n",
      "      \"movbe\",\n",
      "      \"mpx\",\n",
      "      \"msr\",\n",
      "      \"mtrr\",\n",
      "      \"osxsave\",\n",
      "      \"pae\",\n",
      "      \"pat\",\n",
      "      \"pbe\",\n",
      "      \"pcid\",\n",
      "      \"pclmulqdq\",\n",
      "      \"pdcm\",\n",
      "      \"pge\",\n",
      "      \"pni\",\n",
      "      \"popcnt\",\n",
      "      \"pse\",\n",
      "      \"pse36\",\n",
      "      \"rdrnd\",\n",
      "      \"rdseed\",\n",
      "      \"rtm\",\n",
      "      \"sep\",\n",
      "      \"serial\",\n",
      "      \"sgx\",\n",
      "      \"sgx_lc\",\n",
      "      \"smap\",\n",
      "      \"smep\",\n",
      "      \"ss\",\n",
      "      \"sse\",\n",
      "      \"sse2\",\n",
      "      \"sse4_1\",\n",
      "      \"sse4_2\",\n",
      "      \"ssse3\",\n",
      "      \"tm\",\n",
      "      \"tm2\",\n",
      "      \"tsc\",\n",
      "      \"vme\",\n",
      "      \"x2apic\",\n",
      "      \"xsave\",\n",
      "      \"xtpr\"\n",
      "    ],\n",
      "    \"processor\": \"Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\"\n",
      "  },\n",
      "  \"memory\": {\n",
      "    \"total\": 16971276288,\n",
      "    \"available\": 6431543296\n",
      "  },\n",
      "  \"python\": \"3.6.10.final.0 (64 bit)\",\n",
      "  \"os\": \"Windows-10-10.0.19041-SP0\",\n",
      "  \"onnxruntime\": {\n",
      "    \"version\": \"1.5.1\",\n",
      "    \"support_gpu\": false\n",
      "  },\n",
      "  \"onnxruntime_tools\": {\n",
      "    \"version\": \"1.4.4\"\n",
      "  },\n",
      "  \"pytorch\": {\n",
      "    \"version\": \"1.6.0+cpu\",\n",
      "    \"support_gpu\": false,\n",
      "    \"cuda\": null\n",
      "  },\n",
      "  \"tensorflow\": {\n",
      "    \"version\": \"2.3.0\",\n",
      "    \"git_version\": \"v2.3.0-rc2-23-gb36436b087\",\n",
      "    \"support_gpu\": true\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-30 18:49:40.600527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m onnxruntime.transformers.machine_info --silent"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
